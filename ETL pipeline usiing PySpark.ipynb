{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pyspark\n",
      "  Downloading pyspark-3.5.5.tar.gz (317.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.2/317.2 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting py4j==0.10.9.7 (from pyspark)\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "Building wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.5.5-py2.py3-none-any.whl size=317747883 sha256=de08859c269a8c0a677132479fff61dc9b6d1530ff601ea110420e7128787f0a\n",
      "  Stored in directory: /Users/allullaswarantej/Library/Caches/pip/wheels/af/de/65/358d44d6c11fd5795dcbda700ff8b7ab3cbcdfde7f4fb1d9fb\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.7 pyspark-3.5.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/26 15:42:15 WARN Utils: Your hostname, Allullas-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.0.102 instead (on interface en0)\n",
      "25/03/26 15:42:15 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/26 15:42:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ETL Pipeline\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ObjectId: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- ISO2: string (nullable = true)\n",
      " |-- ISO3: string (nullable = true)\n",
      " |-- F1961: double (nullable = true)\n",
      " |-- F1962: double (nullable = true)\n",
      " |-- F1963: double (nullable = true)\n",
      " |-- F1964: double (nullable = true)\n",
      " |-- F1965: double (nullable = true)\n",
      " |-- F1966: double (nullable = true)\n",
      " |-- F1967: double (nullable = true)\n",
      " |-- F1968: double (nullable = true)\n",
      " |-- F1969: double (nullable = true)\n",
      " |-- F1970: double (nullable = true)\n",
      " |-- F1971: double (nullable = true)\n",
      " |-- F1972: double (nullable = true)\n",
      " |-- F1973: double (nullable = true)\n",
      " |-- F1974: double (nullable = true)\n",
      " |-- F1975: double (nullable = true)\n",
      " |-- F1976: double (nullable = true)\n",
      " |-- F1977: double (nullable = true)\n",
      " |-- F1978: double (nullable = true)\n",
      " |-- F1979: double (nullable = true)\n",
      " |-- F1980: double (nullable = true)\n",
      " |-- F1981: double (nullable = true)\n",
      " |-- F1982: double (nullable = true)\n",
      " |-- F1983: double (nullable = true)\n",
      " |-- F1984: double (nullable = true)\n",
      " |-- F1985: double (nullable = true)\n",
      " |-- F1986: double (nullable = true)\n",
      " |-- F1987: double (nullable = true)\n",
      " |-- F1988: double (nullable = true)\n",
      " |-- F1989: double (nullable = true)\n",
      " |-- F1990: double (nullable = true)\n",
      " |-- F1991: double (nullable = true)\n",
      " |-- F1992: double (nullable = true)\n",
      " |-- F1993: double (nullable = true)\n",
      " |-- F1994: double (nullable = true)\n",
      " |-- F1995: double (nullable = true)\n",
      " |-- F1996: double (nullable = true)\n",
      " |-- F1997: double (nullable = true)\n",
      " |-- F1998: double (nullable = true)\n",
      " |-- F1999: double (nullable = true)\n",
      " |-- F2000: double (nullable = true)\n",
      " |-- F2001: double (nullable = true)\n",
      " |-- F2002: double (nullable = true)\n",
      " |-- F2003: double (nullable = true)\n",
      " |-- F2004: double (nullable = true)\n",
      " |-- F2005: double (nullable = true)\n",
      " |-- F2006: double (nullable = true)\n",
      " |-- F2007: double (nullable = true)\n",
      " |-- F2008: double (nullable = true)\n",
      " |-- F2009: double (nullable = true)\n",
      " |-- F2010: double (nullable = true)\n",
      " |-- F2011: double (nullable = true)\n",
      " |-- F2012: double (nullable = true)\n",
      " |-- F2013: double (nullable = true)\n",
      " |-- F2014: double (nullable = true)\n",
      " |-- F2015: double (nullable = true)\n",
      " |-- F2016: double (nullable = true)\n",
      " |-- F2017: double (nullable = true)\n",
      " |-- F2018: double (nullable = true)\n",
      " |-- F2019: double (nullable = true)\n",
      " |-- F2020: double (nullable = true)\n",
      " |-- F2021: double (nullable = true)\n",
      " |-- F2022: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/26 15:46:51 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+----+----+------+------+------+------+------+-----+------+------+------+------+------+------+------+------+------+------+------+------+-----+------+------+------+------+------+------+------+------+-----+------+-----+------+------+------+-----+------+------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+\n",
      "|ObjectId|             Country|ISO2|ISO3| F1961| F1962| F1963| F1964| F1965|F1966| F1967| F1968| F1969| F1970| F1971| F1972| F1973| F1974| F1975| F1976| F1977| F1978|F1979| F1980| F1981| F1982| F1983| F1984| F1985| F1986| F1987|F1988| F1989|F1990| F1991| F1992| F1993|F1994| F1995| F1996|F1997|F1998|F1999|F2000|F2001|F2002|F2003|F2004|F2005|F2006|F2007|F2008|F2009|F2010|F2011|F2012|F2013|F2014|F2015|F2016|F2017|F2018|F2019|F2020|F2021|F2022|\n",
      "+--------+--------------------+----+----+------+------+------+------+------+-----+------+------+------+------+------+------+------+------+------+------+------+------+-----+------+------+------+------+------+------+------+------+-----+------+-----+------+------+------+-----+------+------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+\n",
      "|       1|Afghanistan, Isla...|  AF| AFG|-0.113|-0.164| 0.847|-0.764|-0.244|0.226|-0.371|-0.423|-0.539| 0.813| 0.619|-1.124| 0.232|-0.489|-0.445|-0.286| 0.513| 0.129|0.361|   0.6| 0.483|-0.346| 0.164| 0.145| 0.283|-0.141| 0.391|0.919|-0.205| 0.73|-0.168|-0.294|  0.22| 0.43| 0.359|-0.116|0.471|0.675|1.198|0.993|1.311|1.365|0.587|1.373|0.401| 1.72|0.675|0.704|0.895|1.613|1.397|0.223|1.281|0.456|1.093|1.555| 1.54|1.544| 0.91|0.498|1.327|2.012|\n",
      "|       2|             Albania|  AL| ALB| 0.627| 0.326| 0.075|-0.166|-0.388|0.559|-0.074| 0.081|-0.013|-0.106|-0.195|-0.069|-0.288|-0.139|-0.211|-0.683| 0.545|-0.814|0.203|-0.414|-0.351| 0.173|-0.128| -0.27|-0.103| 0.569|-0.106| 0.37|-0.066|0.795|-0.269| 0.106| 0.076| 1.33|-0.172|-0.038|0.075|0.795| 0.67|1.065|1.532|0.492| 0.97|0.444|0.189|0.345|1.316|0.978| 0.91|1.191|1.055|1.487|1.333|1.198|1.569|1.464|1.121|2.028|1.675|1.498|1.536|1.518|\n",
      "|       3|             Algeria|  DZ| DZA| 0.164| 0.114| 0.077|  0.25|  -0.1|0.433|-0.026|-0.067| 0.291| 0.116|-0.385|-0.348|-0.015|-0.503|-0.539|-0.782| 0.504| 0.012|0.654| 0.232| 0.215| 0.399|  0.56|-0.004| 0.508| 0.296| 0.975|1.304| 0.386|1.266| 0.031|-0.312| 0.552|0.732| 0.595| 0.846|1.059|1.109|1.476| 0.82|1.856|1.258|1.585|0.988|1.264|1.395| 1.22|1.185|0.945|2.265|1.398|1.147|1.192| 1.69|1.121|1.757|1.512| 1.21|1.115|1.926| 2.33|1.688|\n",
      "|       4|      American Samoa|  AS| ASM| 0.079|-0.042| 0.169| -0.14|-0.562|0.181|-0.368|-0.187| 0.132|-0.047|-0.477|-0.067|  0.33|-0.308|-0.118|-0.177| 0.156| 0.092|0.341|  0.35| 0.179|  0.28| 0.313| 0.277| 0.256| 0.394| 0.354|0.509| 0.143|0.497| 0.641| 0.344|-0.069|0.189| 0.755| 0.784| NULL| NULL|0.242|0.626|0.904|1.152|0.716|0.191|0.801|0.403|1.032| 0.67| NULL|1.311|0.854|0.924|1.257| 1.17|1.009|1.539|1.435|1.189|1.539| 1.43|1.268|1.256|\n",
      "|       5|Andorra, Principa...|  AD| AND| 0.736| 0.112|-0.752| 0.308| -0.49|0.415| 0.637| 0.018|-0.137| 0.121|-0.326|-0.499| 0.025|-0.371| 0.246|-0.045|-0.093|-0.163|0.058|-0.188| 0.178| 1.044| 0.859|-0.157| 0.059| 0.387| 0.397|0.883| 1.162|1.736| 0.231| 0.386| 0.174|1.508| 1.279|  0.57|1.788|1.018|1.055| 1.05| 1.48|0.835|1.949|0.936|0.851|1.485|1.024|0.946|1.413|0.471|1.677|1.265|0.831|1.946| 1.69| 1.99|1.925|1.919|1.964|2.562|1.533|3.243|\n",
      "+--------+--------------------+----+----+------+------+------+------+------+-----+------+------+------+------+------+------+------+------+------+------+------+------+-----+------+------+------+------+------+------+------+------+-----+------+-----+------+------+------+-----+------+------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the CSV file into a Spark DataFrame\n",
    "file_path = \"/Users/allullaswarantej/Downloads/temperature.csv\"\n",
    "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "# display the schema and preview the data\n",
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values for country codes\n",
    "df = df.fillna({\"ISO2\": \"Unknown\"})\n",
    "\n",
    "# drop rows where all temperature values are null\n",
    "temperature_columns = [col for col in df.columns if col.startswith('F')]\n",
    "df = df.dropna(subset=temperature_columns, how=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+----+----+-----------+\n",
      "|ObjectId|             Country|ISO3|Year|Temperature|\n",
      "+--------+--------------------+----+----+-----------+\n",
      "|       1|Afghanistan, Isla...| AFG|1961|     -0.113|\n",
      "|       1|Afghanistan, Isla...| AFG|1962|     -0.164|\n",
      "|       1|Afghanistan, Isla...| AFG|1963|      0.847|\n",
      "|       1|Afghanistan, Isla...| AFG|1964|     -0.764|\n",
      "|       1|Afghanistan, Isla...| AFG|1965|     -0.244|\n",
      "|       1|Afghanistan, Isla...| AFG|1966|      0.226|\n",
      "|       1|Afghanistan, Isla...| AFG|1967|     -0.371|\n",
      "|       1|Afghanistan, Isla...| AFG|1968|     -0.423|\n",
      "|       1|Afghanistan, Isla...| AFG|1969|     -0.539|\n",
      "|       1|Afghanistan, Isla...| AFG|1970|      0.813|\n",
      "+--------+--------------------+----+----+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "# reshape temperature data to have 'Year' and 'Temperature' columns\n",
    "df_pivot = df.selectExpr(\n",
    "    \"ObjectId\", \"Country\", \"ISO3\",\n",
    "    \"stack(62, \" + \n",
    "    \",\".join([f\"'F{1961 + i}', F{1961 + i}\" for i in range(62)]) +\n",
    "    \") as (Year, Temperature)\"\n",
    ")\n",
    "\n",
    "# convert 'Year' column to integer\n",
    "df_pivot = df_pivot.withColumn(\"Year\", expr(\"int(substring(Year, 2, 4))\"))\n",
    "df_pivot.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"Users/allullaswarantej/Downloads/processed_temperature.parquet\"\n",
    "df_pivot.write.mode(\"overwrite\").parquet(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+----+----+-----------+\n",
      "|ObjectId|             Country|ISO3|Year|Temperature|\n",
      "+--------+--------------------+----+----+-----------+\n",
      "|       1|Afghanistan, Isla...| AFG|1961|     -0.113|\n",
      "|       1|Afghanistan, Isla...| AFG|1962|     -0.164|\n",
      "|       1|Afghanistan, Isla...| AFG|1963|      0.847|\n",
      "|       1|Afghanistan, Isla...| AFG|1964|     -0.764|\n",
      "|       1|Afghanistan, Isla...| AFG|1965|     -0.244|\n",
      "+--------+--------------------+----+----+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the saved parquet file\n",
    "processed_df = spark.read.parquet(output_path)\n",
    "processed_df.show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
